run:
  reduce_outliers: false

model:
  bertopic:
    min_topic_size: 10
    language: english
    top_n_words: 10
    nr_topics: auto
    calculate_probabilities: true

  sentence_transformer: allenai-specter # all-mpnet-base-v2 # allenai-specter # all-MiniLM-L6-v2
  # sentence_transformer: "paraphrase-multilingual-MiniLM-L12-v2"

  dimensionality_reduction:
    choice: umap
    params:
      umap:
        n_neighbors: 20
        n_components: 10
        min_dist: 0.0
        metric: cosine
        low_memory: false
        random_state: 654565

  clustering:
    choice: hdbscan
    params:
      hdbscan:
        min_cluster_size: 3
        #        max_cluster_size: 15
        min_samples: 15
        metric: euclidean
        #        algorithm: generic # comment to use default "best" one
        cluster_selection_method: eom # leaf # eom
        prediction_data: true # do not change this
        gen_min_span_tree: true
      kmeans:
        n_clusters: 20

  vectorizer:
    params:
      stop_words: english
      ngram_range: !!python/tuple [ 1, 2 ]
      max_df: 0.8 # TF upper cap
      min_df: 0.2
      max_features: 10000


  weighting:
    params:
      bm25_weighting: true
      reduce_frequent_words: true


  representation:
    choice: mmr # keybert
    params:
      keybert:
        random_state: 412763287
      mmr:
        diversity: 0.2


